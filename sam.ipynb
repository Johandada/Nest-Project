{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0a24800-1fa8-4609-b2b2-fa41e69a3268",
   "metadata": {},
   "source": [
    "## Segment Anything Model (SAM) initialiseren\n",
    "In dit blok importeren we de benodigde bibliotheken en initialiseren we het SAM-model dat verantwoordelijk is voor de segmentatie.\n",
    "\n",
    "We kiezen voor het vit_h model (Vision Transformer - Huge), de krachtigste versie van SAM.\n",
    "\n",
    "We laden de bijbehorende modelgewichten via het bestand sam_vit_h_4b8939.pth.\n",
    "\n",
    "Tot slot maken we een SamPredictor object aan, waarmee we later segmentatie kunnen uitvoeren op afbeeldingen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d605c7-ebe3-4ea5-82e9-92da5624460d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports en SAM initialiseren ===\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "from segment_anything import SamAutomaticMaskGenerator\n",
    "from PIL import Image\n",
    "\n",
    "sam_checkpoint = \"sam_vit_h_4b8939.pth\" # het .pth bestand met de gewichten van het SAM-model\n",
    "model_type = \"vit_h\" # het type ViT (Vision Transformer) architectuur dat SAM gebruikt\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7be01b-7167-46ef-9d3e-0f3bd8ae4318",
   "metadata": {},
   "source": [
    "##  Afbeelding voorbereiden en klikpunten genereren\n",
    "In dit blok wordt de afbeelding geladen, omgezet naar het juiste kleurformaat (RGB), ingesteld voor gebruik in SAM, en worden meerdere klikpunten gegenereerd rond het midden van de afbeelding. Deze punten vertellen SAM wáár het moet kijken voor segmentatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79fb038-729f-4134-9fba-84c6a9d88b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Afbeelding laden en converteren ===\n",
    "afbeelding = \"half_vrijstaand_type_e (3).png\"\n",
    "image = cv2.imread(f\"Data_nest_uitgesneden/{afbeelding}\")\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Zet de afbeelding om van BGR naar RGB omdat dat handiger is voor SAM (OpenCV laadt standaard in het BGR-kleurformaat wat is niet compatibel met SAM)\n",
    "predictor.set_image(image_rgb)\n",
    "\n",
    "# === Meerdere punten genereren rond het midden ===\n",
    "h, w, _ = image.shape # image is nu een numpy-array van vorm (hoogte, breedte, 3 (met pixelwaarden tussen 0–255 [120, 0, 255]))\n",
    "center_x, center_y = w // 2, h // 2\n",
    "offset = 40 #  hoeveel pixels rond het midden we extra punten willen plaatsen\n",
    "\n",
    "punten = np.array([[center_x + dx, center_y + dy] for dx in [-offset, 0, offset] for dy in [-offset, 0, offset]])\n",
    "labels = np.ones(len(punten))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0d9dcd-aebe-44ca-b860-79d93bb3e80a",
   "metadata": {},
   "source": [
    "## Segmentatie uitvoeren en beste masker selecteren\n",
    "In deze block geven wij de eerder gedefinieerde punten aan het SAM-model (predictor) door om een segmentatie uit te voeren. Het model retourneert meerdere maskers. Elk masker is een mogelijke interpretatie van wat een object kan zijn op basis van de inputpunten. Wij kiesen vervolgens het beste masker op basis van de hoogste confidence score (scores).\n",
    "\n",
    "De score wordt waarschijnlijk bepaald door een paar factoren zoals\n",
    "\n",
    "**Factor**                                           Betekenis\n",
    "\n",
    "**Maskerkwaliteit**                              Hoe scherp/duidelijk is de grens van het masker?\n",
    "\n",
    "**Overeenkomst met inputprompt (klikpunten)**   Ligt het masker goed om de opgegeven punt(en)?\n",
    "\n",
    "**Afsluiting (compleetheid)**                   Is het een gesloten contour, zonder gaten?\n",
    "\n",
    "**Consistentie met features uit de encoder**    Komt het masker overeen met interne kenmerken (textures, randen, vormen)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc0869-6e28-4ea3-94c2-f9d4e587241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Segmentatie uitvoeren ===\n",
    "masks, scores, _ = predictor.predict(\n",
    "    point_coords=punten,\n",
    "    point_labels=labels,\n",
    "    multimask_output=True\n",
    ")\n",
    "beste_mask = masks[np.argmax(scores)] # np.argmax(scores): bepaalt de index van het masker met de hoogste score (dus het meest betrouwbare masker)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13022a-05ea-4b1d-8527-ed0b4f9b2f07",
   "metadata": {},
   "source": [
    "## Gebouw uitsnijden en opslaan\n",
    "We willen de originele afbeelding omzetten naar een versie waarin alleen het segment (het huis) zichtbaar is en de rest transparant wordt. Dit is handig voor:\n",
    "\n",
    "verdere analyse (zoals ramen/deuren zoeken binnen het gebouw),\n",
    "\n",
    "overlay op de originele afbeelding,\n",
    "\n",
    "eenvoudiger gebruik van segmentatie in latere stappen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ddaec1-9b49-4b91-a8d0-006206bc52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RGBA afbeelding maken met alleen het gebouw ===\n",
    "huis_rgba = np.zeros((image_rgb.shape[0], image_rgb.shape[1], 4), dtype=np.uint8) # We maken een nieuwe lege afbeelding van dezelfde hoogte & breedte als de originele (image_rgb).\n",
    "huis_rgba[:, :, :3] = image_rgb # We kopiëren de RGB-waarden van de originele afbeelding.\n",
    "huis_rgba[:, :, 3] = (beste_mask * 255).astype(np.uint8) # beste_mask is een boolean-array (True/False): waar het huis is gedetecteerd.\n",
    "\n",
    "# === Opslaan als PNG met transparantie ===\n",
    "img_pil = Image.fromarray(huis_rgba)\n",
    "img_pil.save(f\"Data_nest_uitgesneden_zonder_achtergrond/{afbeelding}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25f4b16-1cb6-4248-a582-d05f9cd70105",
   "metadata": {},
   "source": [
    "## Segmentatie voorbereiden\n",
    "In dit blok zetten we de afbeelding (image) om naar het RGB-kleurschema, zoals vereist door het SAM-model. Daarna roepen we SamAutomaticMaskGenerator aan om automatisch alle segmenten (objecten) in de afbeelding te detecteren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f41e7cf-ad19-4eff-92f5-ffb634611b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image naar het RGB-kleurschema zetten\n",
    "huis_image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Segmentatie genereren met SAM\n",
    "mask_generator = SamAutomaticMaskGenerator(sam)\n",
    "resultaten = mask_generator.generate(huis_image_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9f5203-8264-4dab-8886-a48000a7e224",
   "metadata": {},
   "source": [
    "## Grootste segment bepalen\n",
    "Hier bepalen we de oppervlakte (in pixels) van elk gesegmenteerd object door het aantal True-waarden in de maskers op te tellen. We nemen het grootste aantal als referentie om later segmenten in \"klein\", \"middelgroot\" en \"groot\" te classificeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47029b9-fb6c-4b68-a0d3-373d2993f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_area = max(np.sum(m[\"segmentation\"]) for m in resultaten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b7a496-739c-439c-b1a8-25e8d950cdc3",
   "metadata": {},
   "source": [
    "## Masker van alleen het gebouw laden\n",
    "We laden de eerder opgeslagen afbeelding met een transparante achtergrond. Het alpha-kanaal (vierde kanaal) vertelt ons welke pixels tot het gebouw horen (alpha > 0). Deze info wordt gebruikt om alleen segmenten binnen het huis toe te staan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d68d40-4e74-42c6-be68-ec197cd47d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "huis_rgba = np.array(Image.open(f\"Data_nest_uitgesneden_zonder_achtergrond/{afbeelding}\"))\n",
    "alpha_mask = huis_rgba[:, :, 3] > 0   # True = gebouw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85713b86-f6aa-444b-bb50-202c7724f5f8",
   "metadata": {},
   "source": [
    "## Kleur toepassen op gebouwsegmenten\n",
    "We doorlopen alle segmenten uit de automatische segmentatie. We combineren elk masker met het gebouwmasker om ervoor te zorgen dat we alleen delen binnen het huis inkleuren. Vervolgens bepalen we de kleur op basis van de grootte van het segment en kleuren de corresponderende pixels in de afbeelding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37dde4d-2ef0-41d4-9020-19b731b259e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in resultaten:\n",
    "    mask = m[\"segmentation\"]\n",
    "    area = np.sum(mask)\n",
    "\n",
    "    # Segmenten buiten het gebouw negeren\n",
    "    geldig_mask = mask & alpha_mask\n",
    "    if np.sum(geldig_mask) < area * 0.5: # Als minder dan 50% van het segment binnen het gebouw ligt, wordt het segment overgeslagen.\n",
    "        continue                         # (Dit voorkomt dat ruis of delen van de achtergrond toch per ongeluk worden ingekleurd.)\n",
    "\n",
    "\n",
    "    # Kleur op basis van grootte\n",
    "    if area < max_area * 0.1:\n",
    "        kleur = [0, 255, 0]      # klein object → groen\n",
    "    elif area < max_area * 0.5:\n",
    "        kleur = [255, 255, 0]    # medium object → geel\n",
    "    else:\n",
    "        kleur = [255, 0, 0]      # groot object → rood\n",
    "\n",
    "    for c in range(3):\n",
    "        huis_image_rgb[:, :, c][geldig_mask] = kleur[c]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac5173a-5737-45a1-ae51-cf3855f71ca0",
   "metadata": {},
   "source": [
    "## Visualisatie\n",
    "Tot slot tonen we het resultaat: de originele afbeelding van het huis waarin de gesegmenteerde onderdelen zijn ingekleurd op basis van hun grootte (zonder de achtergrond te kleuren). Hiermee krijgen we visueel inzicht in de structuur van het gebouw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d978f7-5bb4-436e-a6b0-d62cea58d8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(huis_image_rgb)\n",
    "plt.title(\"Segmentatie gekleurd op originele afbeelding\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9330c1c1-4c63-4507-9eeb-17a6f46f558b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(huis_image_rgb).save(f\"Data_nest_uitgesneden_output/{afbeelding}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
